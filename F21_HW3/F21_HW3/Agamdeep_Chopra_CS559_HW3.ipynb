{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50285124",
   "metadata": {},
   "source": [
    "# <center> CS559 Homework#3: Decision Tree and Ensemble Methods</center>\n",
    "## <center> Due: 11/8/2021 Monday at 11:59 PM</center>\n",
    "\n",
    "\n",
    "In this assignment, you are going to implement four classifiers - **decision tree, random forest, adaboost, and gradient boost**. \n",
    "Then check the performance with `sklearn` built-in algorithms.\n",
    "In this work, splitting into train and test sets is not necessary. \n",
    "\n",
    "The provided data has four columns - three features (a, b, and c) and the target (class). Three features are continuous data and the target is a binary, 0 or 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea995c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score,classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7a70464",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./F21_CS559_HW3_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92e63c63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.4202</td>\n",
       "      <td>-4.3507</td>\n",
       "      <td>10.3764</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.7044</td>\n",
       "      <td>-4.4601</td>\n",
       "      <td>10.6803</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.8075</td>\n",
       "      <td>-4.0894</td>\n",
       "      <td>10.6259</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.2771</td>\n",
       "      <td>-4.0349</td>\n",
       "      <td>10.1166</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.6447</td>\n",
       "      <td>-3.5968</td>\n",
       "      <td>10.2936</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        a       b        c  class\n",
       "0  9.4202 -4.3507  10.3764      1\n",
       "1  9.7044 -4.4601  10.6803      1\n",
       "2  9.8075 -4.0894  10.6259      1\n",
       "3  9.2771 -4.0349  10.1166      1\n",
       "4  9.6447 -3.5968  10.2936      1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c651b0",
   "metadata": {},
   "source": [
    "### Question 1: Decisition Tree Classifier\n",
    "- A simple DT implementation (10 pts.)\n",
    "    - to make the problem simple, implement a decision tree with depth of 3 (the root index is 0).\n",
    "    - calculate the gini index for each attribute and pick the best attribute for each node.\n",
    "    - calculate the accuracy using accuracy score. \n",
    "- Classification using DecistionTreeClassifier (5 pts)\n",
    "- Evaluation (5 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "be3c7f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini_index(y): \n",
    "    #print(y.shape)\n",
    "    p_net = np.unique(y,return_counts=True,axis=0)[1] / y.shape[0]\n",
    "    #print(p_net, y.shape[1])\n",
    "    return 1 - np.sum([p_i**2 for p_i in p_net]) # min = 0 if node is pure, max = 0.5 if node has equal distribution\n",
    "\n",
    "def most_freq_class(y):\n",
    "    unique_class, freq = np.unique(y, return_counts=True)\n",
    "    sorted_idx = np.argsort(freq)[::-1]\n",
    "    sorted_class = unique_class[sorted_idx]\n",
    "    return sorted_class[0]\n",
    "\n",
    "class Node():  \n",
    "    def __init__(self, leaf_value = None, feat_idx = None, alpha = None, node_left = None, node_right = None):    \n",
    "        self.leaf_value = leaf_value\n",
    "        if self.leaf_value == None:\n",
    "            self.feat_idx = feat_idx\n",
    "            self.alpha = alpha\n",
    "            self.node_left = node_left\n",
    "            self.node_right = node_right\n",
    "            self.dead_end = False\n",
    "        else:\n",
    "            self.dead_end = True\n",
    "            \n",
    "class my_DecisionTreeClassifier():\n",
    "    def __init__(self, max_depth = 3):\n",
    "        self.max_depth = max_depth\n",
    "        self.root = None\n",
    "              \n",
    "    def fit(self, x, y):\n",
    "        self.root = self.grow(x,y,0)\n",
    "        \n",
    "    def grow(self,x,y,depth):\n",
    "        num_feat = x.shape[1]\n",
    "        num_class = len(np.unique(y))\n",
    "        if depth >= self.max_depth or num_class <= 1:\n",
    "            #print(most_freq_class(y))\n",
    "            return Node(leaf_value = most_freq_class(y))\n",
    "        score = 1\n",
    "        for i in range(num_feat):\n",
    "            x_i = x[:,i]\n",
    "            for alpha in x_i:\n",
    "                idx_left =  np.argwhere(x_i <= alpha)\n",
    "                idx_right = np.argwhere(x_i > alpha)\n",
    "                gini_left = gini_index(y[idx_left])\n",
    "                gini_right = gini_index(y[idx_right])\n",
    "                left_size = 0\n",
    "                for a in x_i:\n",
    "                    if a <= alpha:\n",
    "                        left_size += 1\n",
    "                right_size = len(y) - left_size\n",
    "                weighted_gini_idx = (1/len(y))*((left_size*gini_left)+(right_size*gini_right))\n",
    "                if weighted_gini_idx < score:\n",
    "                    score = weighted_gini_idx\n",
    "                    feat_idx = i\n",
    "                    alpha_best = alpha\n",
    "        idx_left =  np.argwhere(x[:,feat_idx] <= alpha_best).squeeze()\n",
    "        idx_right = np.argwhere(x[:,feat_idx] > alpha_best).squeeze()\n",
    "        #print(idx_left.shape, idx_right.shape)\n",
    "        node_left = self.grow(x[idx_left,:],y[idx_left],depth+1)\n",
    "        node_right = self.grow(x[idx_right,:],y[idx_right],depth+1)\n",
    "        return Node(feat_idx = feat_idx, alpha = alpha_best, node_left = node_left, node_right = node_right)  \n",
    "                \n",
    "    def accuracy(self, x, y):\n",
    "        yp = self.forward(x)\n",
    "        return accuracy_score(y,yp)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        return np.array([self.flow(i,self.root) for i in x]).squeeze()\n",
    "    \n",
    "    def flow(self,x_i,node):\n",
    "        if node.dead_end:\n",
    "            return node.leaf_value\n",
    "        elif x_i[node.feat_idx] <= node.alpha:\n",
    "            return self.flow(x_i,node.node_left)\n",
    "        else:\n",
    "            return self.flow(x_i,node.node_right)\n",
    "        \n",
    "#a = np.matrix((1,1,1,2,2)).T\n",
    "#gini_index(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "cae1e694",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(df[['a','b','c']])\n",
    "y = np.array(df[['class']]).squeeze()\n",
    "my_tree = my_DecisionTreeClassifier()\n",
    "my_tree.fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "eefc8830",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my accuracy = 0.9996\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00      1249\n",
      "           2       1.00      1.00      1.00      1251\n",
      "\n",
      "    accuracy                           1.00      2500\n",
      "   macro avg       1.00      1.00      1.00      2500\n",
      "weighted avg       1.00      1.00      1.00      2500\n",
      "\n",
      "[[1249    0]\n",
      " [   1 1250]]\n"
     ]
    }
   ],
   "source": [
    "print('my accuracy =',my_tree.accuracy(x,y))\n",
    "print(classification_report(y, my_tree.forward(x)))\n",
    "print(confusion_matrix(y, my_tree.forward(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1005a5",
   "metadata": {},
   "source": [
    "### Question 2: Random Forest Classifier\n",
    "- A simle RF implementation (10 pts)\n",
    "    - make a bootstrap baggin function to make 3 samples.\n",
    "    - for each sample, run a simple DT from question 1.\n",
    "    - then average the accuracy. \n",
    "- Classification using RandomForestClassifier (5 pts)\n",
    "- Evaluation (5 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "a10f7622",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import mode\n",
    "\n",
    "def my_bootstrap_baggin(x,y):\n",
    "    N = len(y)\n",
    "    idx = np.unique(np.random.choice(N,size=N,replace=True))\n",
    "    return x[idx], y[idx]\n",
    "\n",
    "class my_RandomForestClassifier():\n",
    "    def __init__(self):\n",
    "        self.n_samples = 3\n",
    "        self.depth = 3\n",
    "        self.DT_list = []\n",
    "        \n",
    "    def fit(self,x,y):\n",
    "        for _ in range(self.n_samples):\n",
    "            DT = DecisionTreeClassifier(max_depth=self.depth)\n",
    "            xb,yb=my_bootstrap_baggin(x,y)\n",
    "            DT.fit(xb,yb)\n",
    "            self.DT_list.append(DT)\n",
    "            \n",
    "    def forward(self,x):\n",
    "        y_raw = np.zeros((x.shape[0], self.n_samples))\n",
    "        for i in range(self.n_samples):\n",
    "            y_raw[:,i] = self.DT_list[i].predict(x)\n",
    "        return self.mode(y_raw)\n",
    "    \n",
    "    def mode(self,y_raw):\n",
    "        return mode(y_raw,axis=1)[0].flatten()\n",
    "    \n",
    "    def accuracy(self,x,y):\n",
    "        yp = self.forward(x)\n",
    "        return accuracy_score(y,yp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "1eaffac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_RF = my_RandomForestClassifier()\n",
    "my_RF.fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "5a47297f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my accuracy = 0.9992\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00      1249\n",
      "           2       1.00      1.00      1.00      1251\n",
      "\n",
      "    accuracy                           1.00      2500\n",
      "   macro avg       1.00      1.00      1.00      2500\n",
      "weighted avg       1.00      1.00      1.00      2500\n",
      "\n",
      "[[1249    0]\n",
      " [   2 1249]]\n"
     ]
    }
   ],
   "source": [
    "x = np.array(df[['a','b','c']])\n",
    "y = np.array(df[['class']]).flatten()\n",
    "print('my accuracy =',my_RF.accuracy(x,y))\n",
    "print(classification_report(y, my_RF.forward(x)))\n",
    "print(confusion_matrix(y, my_RF.forward(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a391ec",
   "metadata": {},
   "source": [
    "### Question 3: AdaBoost Classifier\n",
    "- AB implementation (15 pts)\n",
    "- Classification using AdaBoostClassifier (5 pts)\n",
    "- Evaluation (5 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "d0786a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "class my_AdaBoostClassifier():\n",
    "    def __init__(self):\n",
    "        self.w = None\n",
    "        self.H = []\n",
    "        \n",
    "    def fit(self,x,y):\n",
    "        #sigma wi = 1/n for idx 0\n",
    "        self.w = np.ones(x.shape[0])/x.shape[0]\n",
    "        flag = True\n",
    "        while flag:\n",
    "            #calc h and e\n",
    "            w_temp = self.w\n",
    "            stump = DecisionTreeClassifier(max_depth=1,max_leaf_nodes=2)\n",
    "            stump.fit(x,y,sample_weight=w_temp)\n",
    "            yp = stump.predict(x)\n",
    "            e = np.sum(w_temp * y!=yp) #/x.shape[0]\n",
    "            self.H.append(stump)\n",
    "            if e >= 0.5:\n",
    "                flag = False\n",
    "            #calc alpha, Ht+1, wi, Vi\n",
    "            alpha = (1/2)*np.log((1-e)/e)\n",
    "            self.w = (self.w*np.exp(-alpha*stump.predict(x)*y))/(2*np.sqrt(e*(1-e)))\n",
    "        \n",
    "    def forward(self,x):\n",
    "        yp_raw = np.array([h.predict(x) for h in self.H])\n",
    "        return self.mode(yp_raw)\n",
    "    \n",
    "    def mode(self,y_raw):\n",
    "        return mode(y_raw,axis=0)[0].flatten()\n",
    "    \n",
    "    def accuracy(self,x,y):\n",
    "        yp = self.forward(x)\n",
    "        return accuracy_score(y,yp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "235fbb9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(df[['a','b','c']])\n",
    "y = np.array(df[['class']]).flatten()\n",
    "y_pass = np.array([-1 if yt == 1 else 1 for yt in y]).flatten()\n",
    "my_AB = my_AdaBoostClassifier()\n",
    "my_AB.fit(x,y_pass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "bd504545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my accuracy = 0.9032\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.84      0.99      0.91      1249\n",
      "           1       0.99      0.82      0.89      1251\n",
      "\n",
      "    accuracy                           0.90      2500\n",
      "   macro avg       0.92      0.90      0.90      2500\n",
      "weighted avg       0.92      0.90      0.90      2500\n",
      "\n",
      "[[1236   13]\n",
      " [ 229 1022]]\n"
     ]
    }
   ],
   "source": [
    "print('my accuracy =',my_AB.accuracy(x,y_pass))\n",
    "print(classification_report(y_pass, my_AB.forward(x)))\n",
    "print(confusion_matrix(y_pass, my_AB.forward(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1c6dba",
   "metadata": {},
   "source": [
    "### Question 4: Gradient Boost Classifier\n",
    "- GB implementation (15 pts)\n",
    "- Classification using GradientBoostingClassifier (5 pts)\n",
    "- Evaluation (5 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "81099809",
   "metadata": {},
   "outputs": [],
   "source": [
    "class my_GradientBoostingClassifier():\n",
    "    def __init__(self, max_depth = 4):\n",
    "        self.H = None\n",
    "        self.depth = max_depth\n",
    "        \n",
    "    def fit(self,x,y,epochs=10,alpha=0.01):\n",
    "        yp = np.full(y.shape, np.mean(y)).flatten()\n",
    "        for _ in range(epochs):\n",
    "            t = y - yp\n",
    "            h = DecisionTreeRegressor(max_depth=self.depth)\n",
    "            h.fit(x,t)\n",
    "            self.H = h\n",
    "            dy = h.predict(x)\n",
    "            yp -= alpha*dy\n",
    "        \n",
    "    def forward(self,x):\n",
    "        return np.array([2 if ypi > 0 else 1 for ypi in self.H.predict(x)]).flatten()\n",
    "    \n",
    "    def accuracy(self,x,y):\n",
    "        yp =  self.forward(x)\n",
    "        return accuracy_score(y,yp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "5a529ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(df[['a','b','c']])\n",
    "y = np.array(df[['class']]).flatten()\n",
    "my_GB = my_GradientBoostingClassifier()\n",
    "my_GB.fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "59d95196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my accuracy = 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00      1249\n",
      "           2       1.00      1.00      1.00      1251\n",
      "\n",
      "    accuracy                           1.00      2500\n",
      "   macro avg       1.00      1.00      1.00      2500\n",
      "weighted avg       1.00      1.00      1.00      2500\n",
      "\n",
      "[[1249    0]\n",
      " [   0 1251]]\n"
     ]
    }
   ],
   "source": [
    "print('my accuracy =',my_GB.accuracy(x,y))\n",
    "print(classification_report(y, my_GB.forward(x)))\n",
    "print(confusion_matrix(y, my_GB.forward(x)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
